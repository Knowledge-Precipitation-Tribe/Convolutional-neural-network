# Shuffled Grouped Convolution

随机分组卷积在Magvii Inc（Face ++）的[ShuffleNet](https://arxiv.org/abs/1707.01083)中引入。ShuffleNet是一种计算效率高的卷积体系结构，是专为计算能力非常有限（例如10–150 MFLOP）的移动设备设计的。

重组分组卷积背后的思想与分组卷积背后的思想（例如在MobileNet和ResNeXt中使用）和深度可分离卷积（在Xception中使用）相关联。

在关于分组卷积的部分中，我们知道filter被分为不同的组。每个组负责一定深度的常规2D卷积。总操作量大大减少。对于下图中的示例，我们有3个过滤器组。第一个filter组与输入层中的红色部分卷积。类似地，第二和第三filter组与输入中的绿色和蓝色部分卷积。每个滤波器组的内核深度仅为输入层中总通道数的1/3。在此示例中，在第一次分组卷积GConv1之后，将输入层映射到中间特征图。然后，此特征图通过第二个分组卷积GConv2映射到输出层。

![](../../.gitbook/assets/image%20%28117%29.png)

分组卷积的计算效率很高。但是问题在于，每个过滤器组仅处理从先前层中的固定部分向下传递的信息。例如上图中的示例，第一个过滤器组（红色）仅处理从前1/3个输入通道向下传递的信息。蓝色过滤器组（蓝色）仅处理从最后1/3个输入通道向下传递的信息。因此，每个过滤器组仅限于学习一些特定功能。此属性会阻止频道组之间的信息流，并在训练期间削弱表示。为了克服这个问题，我们应用了通道混洗。

通道随机播放的想法是，我们希望混合来自不同过滤器组的信息。在下图中，在将第一个分组卷积GConv1与3个过滤器组一起应用后，我们得到了特征图。在将此特征图馈入第二组卷积之前，我们首先将每组中的通道划分为几个子组。我们将这些子组混合在一起。

![](../../.gitbook/assets/image%20%28121%29.png)

经过这种混洗之后，我们将照常继续执行第二个分组卷积GConv2。但是现在，由于混洗层中的信息已经混合在一起，因此我们基本上将GConv2中的每个组与要素地图层（或输入层）中的不同子组一起提供。结果，我们允许信息在渠道组之间流动，并加强了表示。

